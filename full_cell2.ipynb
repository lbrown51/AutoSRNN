{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vid = imageio.get_reader(\"./vids/Street.mp4\", 'FFMPEG')\n",
    "full_width, full_height = vid.get_meta_data()['size']\n",
    "iter_vid = vid.iter_data()\n",
    "first = np.array(next(iter_vid)/255, dtype=np.float32)\n",
    "second = np.array(next(iter_vid)/255, dtype=np.float32)\n",
    "\n",
    "\n",
    "num_objects = 20\n",
    "num_blocks = 100\n",
    "channels=3\n",
    "batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class r3Cell(tf.nn.rnn_cell.RNNCell):\n",
    "    def __init__(self, num_blocks, num_objects, score_fr_shp):\n",
    "        self._num_blocks = num_blocks\n",
    "        self._num_objects = num_objects\n",
    "        self.score_fr_shp = score_fr_shp\n",
    "    @property\n",
    "    def input_size(self):\n",
    "        return self._num_blocks*self._num_objects\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_blocks*self._num_objects\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return 2*self._num_blocks*self._num_objects\n",
    "    \n",
    "    \n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        \n",
    "        initializer = tf.random_uniform_initializer(-0.1, 0.1, dtype=tf.float32)\n",
    "\n",
    "        def get_variable(name, shape):\n",
    "                return tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\n",
    "\n",
    "        # LSTM Setup\n",
    "        with tf.variable_scope(\"lstm_setup\"):\n",
    "            num_objects, num_blocks = self._num_objects, self._num_blocks\n",
    "            score_fr = tf.reshape(inputs, self.score_fr_shp) \n",
    "            height, width = score_fr.get_shape()[1:3]\n",
    "            g = h = tf.tanh\n",
    "            \n",
    "            c_prev, y_prev = tf.split(1, 2, state)\n",
    "            y_prev = tf.reshape(y_prev, [num_objects, num_blocks])\n",
    "            c_prev = tf.reshape(c_prev, [num_objects, num_blocks])\n",
    "            \n",
    "            def ex(m1, m2):\n",
    "                return tf.einsum('bjki,ijkm-> im', m1, m2)\n",
    "\n",
    "            def ey(m1, m2):\n",
    "                return tf.einsum('ij,ijl->il', m1, m2)\n",
    "            \n",
    "        # LSTM Forget\n",
    "        with tf.variable_scope(\"forget\"):\n",
    "            W_f = get_variable(\"W_f\", [self._num_objects, height, width, num_blocks])\n",
    "            R_f = get_variable(\"R_f\", [num_objects, num_blocks, num_blocks])\n",
    "            b_f = get_variable(\"b_f\", [num_objects, num_blocks])\n",
    "            f = tf.sigmoid(ex(score_fr, W_f) + ey(y_prev, R_f) + b_f)\n",
    "        \n",
    "        # LSTM Input Layer\n",
    "        with tf.variable_scope(\"input\"):\n",
    "            W_i = get_variable(\"W_i\", [num_objects, height, width, num_blocks])\n",
    "            R_i = get_variable(\"R_i\", [num_objects, num_blocks, num_blocks])\n",
    "            b_i = get_variable(\"b_i\", [num_objects, num_blocks])\n",
    "            i = tf.sigmoid(ex(score_fr, W_i) + ey(y_prev, R_i) + b_i)\n",
    "            \n",
    "        # LSTM Candidate Values (Block Input)\n",
    "        with tf.variable_scope(\"candidate\"):\n",
    "            W_z = get_variable(\"W_z\", [num_objects, height, width, num_blocks])\n",
    "            R_z = get_variable(\"R_z\", [num_objects, num_blocks, num_blocks])\n",
    "            b_z = get_variable(\"b_z\", [num_objects, num_blocks])\n",
    "            z = g(ex(score_fr, W_z) + ey(y_prev, R_z) + b_z)\n",
    "            \n",
    "        # LSTM Output Gate\n",
    "        with tf.variable_scope(\"output\"):\n",
    "            W_o = get_variable(\"W_o\", [num_objects, height, width, num_blocks])\n",
    "            R_o = get_variable(\"R_o\", [num_objects, num_blocks, num_blocks])\n",
    "            b_o = get_variable(\"b_o\", [num_objects, num_blocks])\n",
    "            o = tf.sigmoid(ex(score_fr, W_o) + ey(y_prev, R_o) + b_o)\n",
    "        \n",
    "        # LSTM New State\n",
    "        with tf.variable_scope(\"new_state\"):\n",
    "            \n",
    "            c = tf.mul(i, z) + tf.mul(f, c_prev)\n",
    "            y = tf.mul(h(c), o)\n",
    "           \n",
    "        return tf.reshape(y, [1, -1]), tf.concat(1, [tf.reshape(c, [1, -1]), tf.reshape(y, [1, -1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "initializer = tf.random_uniform_initializer(-0.1, 0.1, dtype=tf.float32)\n",
    "\n",
    "def get_variable(name, shape):\n",
    "        return tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\n",
    "\n",
    "def conv2d(x, filter_name, filter_shape):\n",
    "    w = get_variable(filter_name, filter_shape)\n",
    "    return tf.nn.relu(tf.nn.conv2d(x, w, [1, 1, 1, 1], padding=\"SAME\"))\n",
    "\n",
    "def maxPool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "def deconv2d(x, output_shp, filter_name, filter_shape, stride):\n",
    "    w = tf.get_variable(filter_name, filter_shape)\n",
    "    return tf.nn.conv2d_transpose(x, w, output_shp, [1, stride, stride, 1])\n",
    "\n",
    "def fil_sh(p_fshp, fshp, sz=3):\n",
    "    return [sz, sz, p_fshp, fshp]\n",
    "\n",
    "# Inputs\n",
    "with tf.variable_scope(\"inputs\"):\n",
    "    frame = tf.placeholder(tf.float32, [batch, full_height, full_width, channels])\n",
    "    correct = tf.placeholder(tf.float32, [batch, full_height, full_width, channels])\n",
    "\n",
    "# First Convolution\n",
    "with tf.variable_scope(\"conv1\"):\n",
    "    fshp = full_width/2/2/2/2\n",
    "    conv1_1 = conv2d(frame, \"filter1_1\", fil_sh(channels, fshp))\n",
    "    conv1_2 = conv2d(conv1_1, \"filter1_2\", fil_sh(fshp, fshp))\n",
    "    pool1 = maxPool(conv1_2)\n",
    "\n",
    "# Second Convolution\n",
    "with tf.variable_scope(\"conv2\"):\n",
    "    p_fshp = fshp\n",
    "    fshp *= 2\n",
    "    conv2_1 = conv2d(pool1, \"filter2_1\", fil_sh(p_fshp, fshp))\n",
    "    conv2_2 = conv2d(conv2_1, \"filter2_2\", fil_sh(fshp, fshp))\n",
    "    pool2 = maxPool(conv2_2)\n",
    "\n",
    "# Third Convolution\n",
    "with tf.variable_scope(\"conv3\"):\n",
    "    p_fshp = fshp\n",
    "    fshp *= 2\n",
    "    fl_fshp3 = fshp\n",
    "    conv3_1 = conv2d(pool2, \"filter3_1\", fil_sh(p_fshp, fshp))\n",
    "    conv3_2 = conv2d(conv3_1, \"filter3_2\", fil_sh(fshp, fshp))\n",
    "    conv3_3 = conv2d(conv3_2, \"filter3_3\", fil_sh(fshp, fshp))\n",
    "    pool3 = maxPool(conv3_3)\n",
    "\n",
    "# Fourth Convolution\n",
    "with tf.variable_scope(\"conv4\"):\n",
    "    p_fshp = fshp\n",
    "    fshp *= 2\n",
    "    fl_fshp4 = fshp\n",
    "    conv4_1 = conv2d(pool3, \"filter4_1\", fil_sh(p_fshp, fshp))\n",
    "    conv4_2 = conv2d(conv4_1, \"filter4_2\", fil_sh(fshp, fshp))\n",
    "    conv4_3 = conv2d(conv4_2, \"filter4_3\", fil_sh(fshp, fshp))\n",
    "    pool4 = maxPool(conv4_3)\n",
    "\n",
    "# Fifth Convolution\n",
    "with tf.variable_scope(\"conv5\"):\n",
    "    conv5_1 = conv2d(pool4, \"filter5_1\", fil_sh(fshp, fshp))\n",
    "    conv5_2 = conv2d(conv5_1, \"filter5_2\", fil_sh(fshp, fshp))\n",
    "    conv5_3 = conv2d(conv5_2, \"filter5_3\", fil_sh(fshp, fshp))\n",
    "    pool5 = maxPool(conv5_3)\n",
    "\n",
    "# Fully Connected Layers\n",
    "with tf.variable_scope(\"fcn\"):\n",
    "    p_fshp = fshp\n",
    "    fshp = full_width\n",
    "    fcn6 = tf.nn.dropout(conv2d(pool5, \"filter6\", fil_sh(p_fshp, fshp, 7)), .5)\n",
    "    fcn7 = tf.nn.dropout(conv2d(fcn6, \"filter7\", fil_sh(fshp, fshp, 1)), .5)\n",
    "\n",
    "# Score\n",
    "with tf.variable_scope(\"score\"):\n",
    "    p_fshp = fshp\n",
    "    fshp = num_objects\n",
    "    score_fr = conv2d(fcn7, \"filter_scr\", fil_sh(p_fshp, fshp, 1))\n",
    "    inputs = tf.reshape(score_fr, [1, 1, -1])  \n",
    "    score_fr_shp = score_fr.get_shape()\n",
    "\n",
    "cell = r3Cell(num_blocks, num_objects, score_fr_shp)\n",
    "\n",
    "\n",
    "output, state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs, \n",
    "                            dtype=tf.float32)\n",
    "output_rshp = tf.reshape(output, [num_objects, num_blocks])\n",
    "W_nst = get_variable(\"W_nst\", [num_blocks, *score_fr_shp[1:])\n",
    "nst = tf.expand_dims(tf.einsum('ij,jkli->kli', output_rshp, W_nst), axis=0)\n",
    "\n",
    "# Upsampling\n",
    "with tf.variable_scope(\"upsampling\"):\n",
    "    output_shp = tf.stack([*pool4.get_shape()[:3], tf.Dimension(num_objects)])\n",
    "    upscore2 = deconv2d(nst, output_shp, \"defilter2\", fil_sh(fshp, fshp, 4), 2)\n",
    "\n",
    "with tf.variable_scope(\"upsampling_p4\"):\n",
    "    score_pool4 = conv2d(pool4, \"filter_p4\", fil_sh(fl_fshp4, fshp, 1))\n",
    "    fuse_pool4 = tf.add(upscore2, score_pool4)\n",
    "    output_shp = tf.stack([*pool3.get_shape()[:3], tf.Dimension(num_objects)])\n",
    "    upscore_pool4 = deconv2d(fuse_pool4, output_shp, \"defilter4\", fil_sh(fshp, fshp, 4), 2)\n",
    "\n",
    "with tf.variable_scope(\"upsampling_p3\"):\n",
    "    score_pool3 = conv2d(pool3, \"filter_p3\", fil_sh(fl_fshp3, fshp, 1))\n",
    "    fuse_pool3 = tf.add(upscore_pool4, score_pool3)\n",
    "    output_shp = tf.stack([1, full_height, full_width, channels])\n",
    "    upscore8 = deconv2d(fuse_pool3, output_shp, \"defilter8\", fil_sh(channels, fshp, 16), 8)\n",
    "\n",
    "session = tf.Session()\n",
    "loss = tf.reduce_mean(tf.square(tf.sub(second, upscore8)))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "saver = tf.train.Saver()\n",
    "summary_writer = tf.summary.FileWriter('./train', session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}